---
title: 'Graph Conditional Variational Models: Too Complex for Multiagent Trajectories?'
abstract: Recent advances in modeling multiagent trajectories combine graph architectures
  such as graph neural networks (GNNs) with conditional variational models (CVMs)
  such as variational RNNs (VRNNs). Originally, CVMs have been proposed to facilitate
  learning with multi-modal and structured data and thus seem to perfectly match the
  requirements of multi-modal multiagent trajectories with their structured output
  spaces. Empirical results of VRNNs on trajectory data support this assumption. In
  this paper, we revisit experiments and proposed architectures with additional rigour,
  ablation runs and baselines. In contrast to common belief, we show that prior results
  with CVMs on trajectory data might be misleading. Given a neural network with a
  graph architecture and/or structured output function, variational autoencoding does
  not seem to contribute statistically significantly to empirical performance. Instead,
  we show that well-known emission functions do contribute, while coming with less
  complexity, engineering and computation time.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: rudolph20a
month: 0
tex_title: 'Graph Conditional Variational Models: Too Complex for Multiagent Trajectories?'
firstpage: 136
lastpage: 147
page: 136-147
order: 136
cycles: false
bibtex_author: Rudolph, Yannick and Brefeld, Ulf and Dick, Uwe
author:
- given: Yannick
  family: Rudolph
- given: Ulf
  family: Brefeld
- given: Uwe
  family: Dick
date: 2020-02-08
address: 
container-title: Proceedings on "I Can't Believe It's Not Better!" at NeurIPS Workshops
volume: '137'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 2
  - 8
pdf: http://proceedings.mlr.press/v137/rudolph20a/rudolph20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
