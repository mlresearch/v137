---
title: Further Analysis of Outlier Detection with Deep Generative Models
abstract: The recent, counter-intuitive discovery that deep generative models (DGMs)
  can frequently assign a higher likelihood to outliers has implications for both
  outlier detection applications as well as our overall understanding of generative
  modeling. In this work, we present a possible explanation for this phenomenon, starting
  from the observation that a modelâ€™s typical set and high-density region may not
  conincide. From this vantage point we propose a novel outlier test, the empirical
  success of which suggests that the failure of existing likelihood-based outlier
  tests does not necessarily imply that the corresponding generative model is uncalibrated.
  We also conduct additional experiments to help disentangle the impact of low-level
  texture versus high-level semantics in differentiating outliers. In aggregate, these
  results suggest that modifications to the standard evaluation practices and benchmarks
  commonly applied in the literature are needed.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang20a
month: 0
tex_title: Further Analysis of Outlier Detection with Deep Generative Models
firstpage: 11
lastpage: 20
page: 11-20
order: 11
cycles: false
bibtex_author: Wang, Ziyu and Dai, Bin and Wipf, David and Zhu, Jun
author:
- given: Ziyu
  family: Wang
- given: Bin
  family: Dai
- given: David
  family: Wipf
- given: Jun
  family: Zhu
date: 2020-02-08
address: 
container-title: Proceedings on "I Can't Belive It's Not Better!" at NeurIPS Workshop
volume: '137'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 2
  - 8
pdf: http://proceedings.mlr.press/v137/wang20a/wang20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v137/wang20a/wang20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
