---
title: End-to-End Differentiable GANs for Text Generation
abstract: Despite being widely used, text generation models trained with maximum likelihood
  estimation (MLE) suffer from known limitations. Due to a mismatch between training
  and inference, they suffer from exposure bias. Generative adversarial networks (GANs),
  on the other hand, by leveraging a discriminator, can mitigate these limitations.
  However, discrete nature of text makes the model non-differentiable hindering training.
  To deal with this issue, the approaches proposed so far, using reinforcement learning
  or softmax approximatons are unstable and have been shown to underperform MLE. In
  this work, we consider an alternative setup where we represent each word by a pretrained
  vector. We modify the generator to output a sequence of such word vectors and feed
  them directly to the discriminator making the training process differentiable. Through
  experiments on unconditional text generation with Wasserstein GANs, we find that
  while this approach, without any pretraining is more stable while training and outperforms
  other GAN based approaches, it still falls behind MLE. We posit that this gap is
  due to autoregressive nature and architectural requirements for text generation
  as well as a fundamental difference between the definition of Wasserstein distance
  in image and text domains.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kumar20a
month: 0
tex_title: End-to-End Differentiable {GANs} for Text Generation
firstpage: 118
lastpage: 128
page: 118-128
order: 118
cycles: false
editor:
- given: Jessica 
  family: Zosa Forde
- given: Francisco
  family: Ruiz
- given: Melanie F. 
  family: Pradier
- given: Aaron 
  family: Schein
bibtex_author: Kumar, Sachin and Tsvetkov, Yulia
author:
- given: Sachin
  family: Kumar
- given: Yulia
  family: Tsvetkov
date: 2020-02-08
address: 
container-title: Proceedings on "I Can't Believe It's Not Better!" at NeurIPS Workshops
volume: '137'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 2
  - 8
pdf: http://proceedings.mlr.press/v137/kumar20a/kumar20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
