---
title: A case for new neural network smoothness constraints
abstract: How sensitive should machine learning models be to input changes? We tackle
  the question of model smoothness and show that it is a useful inductive bias which
  aids generalization, adversarial robustness, generative modeling and reinforcement
  learning. We explore current methods of imposing smoothness constraints and observe
  they lack the flexibility to adapt to new tasks, they donâ€™t account for data modalities,
  they interact with losses, architectures and optimization in ways not yet fully
  understood. We conclude that new advances in the field are hinging on finding ways
  to incorporate data, tasks and learning into our definitions of smoothness.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: rosca20a
month: 0
tex_title: A case for new neural network smoothness constraints
firstpage: 21
lastpage: 32
page: 21-32
order: 21
cycles: false
editor:
- given: Jessica 
  family: Zosa Forde
- given: Francisco
  family: Ruiz
- given: Melanie F. 
  family: Pradier
- given: Aaron 
  family: Schein
bibtex_author: Rosca, Mihaela and Weber, Theophane and Gretton, Arthur and Mohamed,
  Shakir
author:
- given: Mihaela
  family: Rosca
- given: Theophane
  family: Weber
- given: Arthur
  family: Gretton
- given: Shakir
  family: Mohamed
date: 2020-02-08
address: 
container-title: Proceedings on "I Can't Believe It's Not Better!" at NeurIPS Workshops
volume: '137'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 2
  - 8
pdf: http://proceedings.mlr.press/v137/rosca20a/rosca20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v137/rosca20a/rosca20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
