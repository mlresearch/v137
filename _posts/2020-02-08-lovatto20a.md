---
title: 'Decision-Aware Model Learning for Actor-Critic Methods: When Theory Does Not
  Meet Practice'
abstract: Actor-Critic methods are a prominent class of modern reinforcement learning
  algorithms based on the classic Policy Iteration procedure. Despite many successful
  cases, Actor-Critic methods tend to require a gigantic number of experiences and
  can be very unstable. Recent approaches have advocated learning and using a world
  model to improve sample efficiency and reduce reliance on the value function estimate.
  However, learning an accurate dynamics model of the world remains challenging, often
  requiring computationally costly and data-hungry models. More recent work has shown
  that learning an everywhere accurate model is unnecessary and often detrimental
  to the overall task; instead, the agent should improve the world model on task-critical
  regions. For example, in Iterative Value-Aware Model Learning, the authors extend
  model-based value iteration by incorporating the value function (estimate) into
  the model loss function, showing the novel model objective reflects improved performance
  in the end task. Therefore, it seems natural to expect that model-based Actor-Critic
  methods can benefit equally from learning value-aware models, improving overall
  task performance, or reducing the need for large, expensive models. However, we
  show empirically that combining Actor-Critic and value-aware model learning can
  be quite difficult and that naive approaches such as maximum likelihood estimation
  often achieve superior performance with less computational cost. Our results suggest
  that, despite theoretical guarantees, learning a value-aware model in continuous
  domains does not ensure better performance on the overall task.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lovatto20a
month: 0
tex_title: 'Decision-Aware Model Learning for Actor-Critic Methods: When Theory Does
  Not Meet Practice'
firstpage: 76
lastpage: 86
page: 76-86
order: 76
cycles: false
editor:
- given: Jessica 
  family: Zosa Forde
- given: Francisco
  family: Ruiz
- given: Melanie F. 
  family: Pradier
- given: Aaron 
  family: Schein
bibtex_author: Lovatto, \^{A}ngelo G. and Bueno, Thiago P. and Mau\'{a}, Denis D.
  and de Barros, Leliane N.
author:
- given: Ângelo G.
  family: Lovatto
- given: Thiago P.
  family: Bueno
- given: Denis D.
  family: Mauá
- given: Leliane N.
  family: Barros
date: 2020-02-08
address: 
container-title: Proceedings on "I Can't Believe It's Not Better!" at NeurIPS Workshops
volume: '137'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 2
  - 8
pdf: http://proceedings.mlr.press/v137/lovatto20a/lovatto20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v137/lovatto20a/lovatto20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
